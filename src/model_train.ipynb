{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Text processing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# ML models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n",
    "# Metrics and processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'distutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Deep Learning\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout, LSTM, Embedding\n",
      "File \u001b[0;32m~/Desktop/Projects/prod_model/venv/lib/python3.12/site-packages/tensorflow/__init__.py:30\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03mTop-level module of TensorFlow. By convention, we refer to this module as\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m`tf` instead of `tensorflow`, following the common practice of importing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03mthis file with a file generated from [`api_template.__init__.py`](https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/api_template.__init__.py)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order,protected-access,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_distutils\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_inspect\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'distutils'"
     ]
    }
   ],
   "source": [
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (159571, 8)\n",
      "\n",
      "Columns in dataset: ['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
      "\n",
      "Sample of the data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution:\n",
      "toxic: toxic\n",
      "0    144277\n",
      "1     15294\n",
      "Name: count, dtype: int64\n",
      "severe_toxic: severe_toxic\n",
      "0    157976\n",
      "1      1595\n",
      "Name: count, dtype: int64\n",
      "obscene: obscene\n",
      "0    151122\n",
      "1      8449\n",
      "Name: count, dtype: int64\n",
      "threat: threat\n",
      "0    159093\n",
      "1       478\n",
      "Name: count, dtype: int64\n",
      "insult: insult\n",
      "0    151694\n",
      "1      7877\n",
      "Name: count, dtype: int64\n",
      "identity_hate: identity_hate\n",
      "0    158166\n",
      "1      1405\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "train = pd.read_csv('dataset/train.csv')\n",
    "test = pd.read_csv('dataset/test.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(\"Training set shape:\", train.shape)\n",
    "print(\"\\nColumns in dataset:\", train.columns.tolist())\n",
    "print(\"\\nSample of the data:\")\n",
    "display(train.head())\n",
    "\n",
    "# Check class distribution\n",
    "toxic_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "print(\"\\nClass distribution:\")\n",
    "for column in toxic_columns:\n",
    "    print(f\"{column}: {train[column].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/pranavks/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/pranavks/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Function to clean text data\n",
    "    \"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Apply cleaning to the comment_text column\n",
    "train['cleaned_text'] = train['comment_text'].apply(clean_text)\n",
    "test['cleaned_text'] = test['comment_text'].apply(clean_text)\n",
    "\n",
    "# Create TF-IDF features\n",
    "tfidf = TfidfVectorizer(max_features=10000)\n",
    "X = tfidf.fit_transform(train['cleaned_text'])\n",
    "X_test = tfidf.transform(test['cleaned_text'])\n",
    "\n",
    "# Prepare target variables\n",
    "y = train[toxic_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (127656, 10000)\n",
      "Validation set shape: (31915, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression for toxic\n",
      "Accuracy: 0.9574\n",
      "AUC: 0.8060\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     28859\n",
      "           1       0.91      0.62      0.74      3056\n",
      "\n",
      "    accuracy                           0.96     31915\n",
      "   macro avg       0.93      0.81      0.86     31915\n",
      "weighted avg       0.96      0.96      0.95     31915\n",
      "\n",
      "\n",
      "Training Logistic Regression for severe_toxic\n",
      "Accuracy: 0.9906\n",
      "AUC: 0.6113\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     31594\n",
      "           1       0.58      0.22      0.32       321\n",
      "\n",
      "    accuracy                           0.99     31915\n",
      "   macro avg       0.79      0.61      0.66     31915\n",
      "weighted avg       0.99      0.99      0.99     31915\n",
      "\n",
      "\n",
      "Training Logistic Regression for obscene\n",
      "Accuracy: 0.9763\n",
      "AUC: 0.8068\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     30200\n",
      "           1       0.91      0.62      0.74      1715\n",
      "\n",
      "    accuracy                           0.98     31915\n",
      "   macro avg       0.95      0.81      0.86     31915\n",
      "weighted avg       0.98      0.98      0.97     31915\n",
      "\n",
      "\n",
      "Training Logistic Regression for threat\n",
      "Accuracy: 0.9978\n",
      "AUC: 0.5810\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31841\n",
      "           1       0.63      0.16      0.26        74\n",
      "\n",
      "    accuracy                           1.00     31915\n",
      "   macro avg       0.81      0.58      0.63     31915\n",
      "weighted avg       1.00      1.00      1.00     31915\n",
      "\n",
      "\n",
      "Training Logistic Regression for insult\n",
      "Accuracy: 0.9707\n",
      "AUC: 0.7575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     30301\n",
      "           1       0.84      0.52      0.64      1614\n",
      "\n",
      "    accuracy                           0.97     31915\n",
      "   macro avg       0.91      0.76      0.81     31915\n",
      "weighted avg       0.97      0.97      0.97     31915\n",
      "\n",
      "\n",
      "Training Logistic Regression for identity_hate\n",
      "Accuracy: 0.9917\n",
      "AUC: 0.5729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     31621\n",
      "           1       0.74      0.15      0.24       294\n",
      "\n",
      "    accuracy                           0.99     31915\n",
      "   macro avg       0.87      0.57      0.62     31915\n",
      "weighted avg       0.99      0.99      0.99     31915\n",
      "\n",
      "\n",
      "Training Naive Bayes for toxic\n",
      "Accuracy: 0.9483\n",
      "AUC: 0.7455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     28859\n",
      "           1       0.93      0.49      0.65      3056\n",
      "\n",
      "    accuracy                           0.95     31915\n",
      "   macro avg       0.94      0.75      0.81     31915\n",
      "weighted avg       0.95      0.95      0.94     31915\n",
      "\n",
      "\n",
      "Training Naive Bayes for severe_toxic\n",
      "Accuracy: 0.9904\n",
      "AUC: 0.5588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     31594\n",
      "           1       0.63      0.12      0.20       321\n",
      "\n",
      "    accuracy                           0.99     31915\n",
      "   macro avg       0.81      0.56      0.60     31915\n",
      "weighted avg       0.99      0.99      0.99     31915\n",
      "\n",
      "\n",
      "Training Naive Bayes for obscene\n",
      "Accuracy: 0.9695\n",
      "AUC: 0.7411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     30200\n",
      "           1       0.90      0.49      0.63      1715\n",
      "\n",
      "    accuracy                           0.97     31915\n",
      "   macro avg       0.94      0.74      0.81     31915\n",
      "weighted avg       0.97      0.97      0.97     31915\n",
      "\n",
      "\n",
      "Training Naive Bayes for threat\n",
      "Accuracy: 0.9976\n",
      "AUC: 0.5000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31841\n",
      "           1       0.00      0.00      0.00        74\n",
      "\n",
      "    accuracy                           1.00     31915\n",
      "   macro avg       0.50      0.50      0.50     31915\n",
      "weighted avg       1.00      1.00      1.00     31915\n",
      "\n",
      "\n",
      "Training Naive Bayes for insult\n",
      "Accuracy: 0.9659\n",
      "AUC: 0.6979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     30301\n",
      "           1       0.85      0.40      0.54      1614\n",
      "\n",
      "    accuracy                           0.97     31915\n",
      "   macro avg       0.91      0.70      0.76     31915\n",
      "weighted avg       0.96      0.97      0.96     31915\n",
      "\n",
      "\n",
      "Training Naive Bayes for identity_hate\n",
      "Accuracy: 0.9908\n",
      "AUC: 0.5185\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     31621\n",
      "           1       0.50      0.04      0.07       294\n",
      "\n",
      "    accuracy                           0.99     31915\n",
      "   macro avg       0.75      0.52      0.53     31915\n",
      "weighted avg       0.99      0.99      0.99     31915\n",
      "\n",
      "\n",
      "Training Linear SVM for toxic\n",
      "Accuracy: 0.9605\n",
      "AUC: 0.8402\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     28859\n",
      "           1       0.87      0.69      0.77      3056\n",
      "\n",
      "    accuracy                           0.96     31915\n",
      "   macro avg       0.92      0.84      0.87     31915\n",
      "weighted avg       0.96      0.96      0.96     31915\n",
      "\n",
      "\n",
      "Training Linear SVM for severe_toxic\n",
      "Accuracy: 0.9906\n",
      "AUC: 0.6298\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     31594\n",
      "           1       0.57      0.26      0.36       321\n",
      "\n",
      "    accuracy                           0.99     31915\n",
      "   macro avg       0.78      0.63      0.68     31915\n",
      "weighted avg       0.99      0.99      0.99     31915\n",
      "\n",
      "\n",
      "Training Linear SVM for obscene\n",
      "Accuracy: 0.9785\n",
      "AUC: 0.8407\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     30200\n",
      "           1       0.89      0.69      0.77      1715\n",
      "\n",
      "    accuracy                           0.98     31915\n",
      "   macro avg       0.94      0.84      0.88     31915\n",
      "weighted avg       0.98      0.98      0.98     31915\n",
      "\n",
      "\n",
      "Training Linear SVM for threat\n",
      "Accuracy: 0.9980\n",
      "AUC: 0.6485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31841\n",
      "           1       0.65      0.30      0.41        74\n",
      "\n",
      "    accuracy                           1.00     31915\n",
      "   macro avg       0.82      0.65      0.70     31915\n",
      "weighted avg       1.00      1.00      1.00     31915\n",
      "\n",
      "\n",
      "Training Linear SVM for insult\n",
      "Accuracy: 0.9714\n",
      "AUC: 0.7849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     30301\n",
      "           1       0.80      0.58      0.67      1614\n",
      "\n",
      "    accuracy                           0.97     31915\n",
      "   macro avg       0.89      0.78      0.83     31915\n",
      "weighted avg       0.97      0.97      0.97     31915\n",
      "\n",
      "\n",
      "Training Linear SVM for identity_hate\n",
      "Accuracy: 0.9922\n",
      "AUC: 0.6321\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     31621\n",
      "           1       0.70      0.27      0.39       294\n",
      "\n",
      "    accuracy                           0.99     31915\n",
      "   macro avg       0.85      0.63      0.69     31915\n",
      "weighted avg       0.99      0.99      0.99     31915\n",
      "\n",
      "\n",
      "Training Random Forest for toxic\n",
      "Accuracy: 0.9526\n",
      "AUC: 0.7700\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     28859\n",
      "           1       0.93      0.54      0.69      3056\n",
      "\n",
      "    accuracy                           0.95     31915\n",
      "   macro avg       0.94      0.77      0.83     31915\n",
      "weighted avg       0.95      0.95      0.95     31915\n",
      "\n",
      "\n",
      "Training Random Forest for severe_toxic\n",
      "Accuracy: 0.9900\n",
      "AUC: 0.5324\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     31594\n",
      "           1       0.53      0.07      0.12       321\n",
      "\n",
      "    accuracy                           0.99     31915\n",
      "   macro avg       0.76      0.53      0.56     31915\n",
      "weighted avg       0.99      0.99      0.99     31915\n",
      "\n",
      "\n",
      "Training Random Forest for obscene\n",
      "Accuracy: 0.9773\n",
      "AUC: 0.8227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     30200\n",
      "           1       0.90      0.65      0.75      1715\n",
      "\n",
      "    accuracy                           0.98     31915\n",
      "   macro avg       0.94      0.82      0.87     31915\n",
      "weighted avg       0.98      0.98      0.98     31915\n",
      "\n",
      "\n",
      "Training Random Forest for threat\n",
      "Accuracy: 0.9977\n",
      "AUC: 0.5270\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31841\n",
      "           1       0.50      0.05      0.10        74\n",
      "\n",
      "    accuracy                           1.00     31915\n",
      "   macro avg       0.75      0.53      0.55     31915\n",
      "weighted avg       1.00      1.00      1.00     31915\n",
      "\n",
      "\n",
      "Training Random Forest for insult\n",
      "Accuracy: 0.9677\n",
      "AUC: 0.7281\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     30301\n",
      "           1       0.82      0.46      0.59      1614\n",
      "\n",
      "    accuracy                           0.97     31915\n",
      "   macro avg       0.90      0.73      0.79     31915\n",
      "weighted avg       0.96      0.97      0.96     31915\n",
      "\n",
      "\n",
      "Training Random Forest for identity_hate\n",
      "Accuracy: 0.9915\n",
      "AUC: 0.5526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     31621\n",
      "           1       0.78      0.11      0.19       294\n",
      "\n",
      "    accuracy                           0.99     31915\n",
      "   macro avg       0.88      0.55      0.59     31915\n",
      "weighted avg       0.99      0.99      0.99     31915\n",
      "\n",
      "\n",
      "Training Gradient Boosting for toxic\n",
      "Accuracy: 0.9439\n",
      "AUC: 0.7165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     28859\n",
      "           1       0.95      0.44      0.60      3056\n",
      "\n",
      "    accuracy                           0.94     31915\n",
      "   macro avg       0.95      0.72      0.78     31915\n",
      "weighted avg       0.94      0.94      0.93     31915\n",
      "\n",
      "\n",
      "Training Gradient Boosting for severe_toxic\n",
      "Accuracy: 0.9899\n",
      "AUC: 0.5956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     31594\n",
      "           1       0.50      0.19      0.28       321\n",
      "\n",
      "    accuracy                           0.99     31915\n",
      "   macro avg       0.75      0.60      0.64     31915\n",
      "weighted avg       0.99      0.99      0.99     31915\n",
      "\n",
      "\n",
      "Training Gradient Boosting for obscene\n",
      "Accuracy: 0.9746\n",
      "AUC: 0.7911\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     30200\n",
      "           1       0.91      0.59      0.71      1715\n",
      "\n",
      "    accuracy                           0.97     31915\n",
      "   macro avg       0.94      0.79      0.85     31915\n",
      "weighted avg       0.97      0.97      0.97     31915\n",
      "\n",
      "\n",
      "Training Gradient Boosting for threat\n",
      "Accuracy: 0.9972\n",
      "AUC: 0.5941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31841\n",
      "           1       0.33      0.19      0.24        74\n",
      "\n",
      "    accuracy                           1.00     31915\n",
      "   macro avg       0.66      0.59      0.62     31915\n",
      "weighted avg       1.00      1.00      1.00     31915\n",
      "\n",
      "\n",
      "Training Gradient Boosting for insult\n",
      "Accuracy: 0.9670\n",
      "AUC: 0.7101\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     30301\n",
      "           1       0.85      0.42      0.57      1614\n",
      "\n",
      "    accuracy                           0.97     31915\n",
      "   macro avg       0.91      0.71      0.77     31915\n",
      "weighted avg       0.96      0.97      0.96     31915\n",
      "\n",
      "\n",
      "Training Gradient Boosting for identity_hate\n",
      "Accuracy: 0.9913\n",
      "AUC: 0.6249\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     31621\n",
      "           1       0.56      0.25      0.35       294\n",
      "\n",
      "    accuracy                           0.99     31915\n",
      "   macro avg       0.77      0.62      0.67     31915\n",
      "weighted avg       0.99      0.99      0.99     31915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_evaluate_model(model, X_train, X_val, y_train, y_val, model_name):\n",
    "    \"\"\"\n",
    "    Train and evaluate a model\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Train and evaluate for each toxic category\n",
    "    for i, category in enumerate(toxic_columns):\n",
    "        print(f\"\\nTraining {model_name} for {category}\")\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train[:, i])\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_val)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_val[:, i], y_pred)\n",
    "        auc = roc_auc_score(y_val[:, i], y_pred)\n",
    "        \n",
    "        results.append({\n",
    "            'Category': category,\n",
    "            'Model': model_name,\n",
    "            'Accuracy': accuracy,\n",
    "            'AUC': auc\n",
    "        })\n",
    "        \n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"AUC: {auc:.4f}\")\n",
    "        print(classification_report(y_val[:, i], y_pred))\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Dictionary of traditional ML models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Linear SVM': LinearSVC(max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100),\n",
    "    'Gradient Boosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate all models\n",
    "results_df = pd.DataFrame()\n",
    "for name, model in models.items():\n",
    "    model_results = train_evaluate_model(model, X_train, X_val, y_train, y_val, name)\n",
    "    results_df = pd.concat([results_df, model_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Training Simple Neural Network...\n",
      "\n",
      "Epoch 1/3\n",
      "toxic - Accuracy: 0.9551, AUC: 0.7882\n",
      "severe_toxic - Accuracy: 0.9905, AUC: 0.5404\n",
      "obscene - Accuracy: 0.9754, AUC: 0.8143\n",
      "threat - Accuracy: 0.9977, AUC: 0.5000\n",
      "insult - Accuracy: 0.9682, AUC: 0.7615\n",
      "identity_hate - Accuracy: 0.9908, AUC: 0.5000\n",
      "\n",
      "Epoch 2/3\n",
      "toxic - Accuracy: 0.9585, AUC: 0.8413\n",
      "severe_toxic - Accuracy: 0.9903, AUC: 0.6790\n",
      "obscene - Accuracy: 0.9783, AUC: 0.8651\n",
      "threat - Accuracy: 0.9977, AUC: 0.5000\n",
      "insult - Accuracy: 0.9698, AUC: 0.8257\n",
      "identity_hate - Accuracy: 0.9915, AUC: 0.5593\n",
      "\n",
      "Epoch 3/3\n",
      "toxic - Accuracy: 0.9590, AUC: 0.8319\n",
      "severe_toxic - Accuracy: 0.9906, AUC: 0.5820\n",
      "obscene - Accuracy: 0.9787, AUC: 0.8474\n",
      "threat - Accuracy: 0.9978, AUC: 0.5203\n",
      "insult - Accuracy: 0.9704, AUC: 0.7876\n",
      "identity_hate - Accuracy: 0.9921, AUC: 0.6220\n",
      "\n",
      "Training CNN Model...\n",
      "\n",
      "Epoch 1/3\n",
      "toxic - Accuracy: 0.9525, AUC: 0.7721\n",
      "severe_toxic - Accuracy: 0.9904, AUC: 0.5819\n",
      "obscene - Accuracy: 0.9753, AUC: 0.8055\n",
      "threat - Accuracy: 0.9978, AUC: 0.6012\n",
      "insult - Accuracy: 0.9707, AUC: 0.7714\n",
      "identity_hate - Accuracy: 0.9919, AUC: 0.5848\n",
      "\n",
      "Epoch 2/3\n",
      "toxic - Accuracy: 0.9588, AUC: 0.8249\n",
      "severe_toxic - Accuracy: 0.9901, AUC: 0.5448\n",
      "obscene - Accuracy: 0.9787, AUC: 0.8557\n",
      "threat - Accuracy: 0.9979, AUC: 0.5945\n",
      "insult - Accuracy: 0.9721, AUC: 0.7891\n",
      "identity_hate - Accuracy: 0.9920, AUC: 0.6118\n",
      "\n",
      "Epoch 3/3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Custom Dataset class for PyTorch\n",
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.labels = torch.FloatTensor(labels)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'features': self.features[idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "\n",
    "# Define model architectures\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 256)\n",
    "        self.layer2 = nn.Linear(256, 128)\n",
    "        self.layer3 = nn.Linear(128, 6)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.layer3(x))\n",
    "        return x\n",
    "\n",
    "class CNNTextClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.fc1 = nn.Linear(input_dim * 16, 256)\n",
    "        self.fc2 = nn.Linear(256, 6)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, n_epochs, model_name):\n",
    "    results = []\n",
    "    model = model.to(device)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{n_epochs}\")\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch in train_loader:\n",
    "            features = batch['features'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_predictions = []\n",
    "        val_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                features = batch['features'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                \n",
    "                outputs = model(features)\n",
    "                predictions = (outputs > 0.5).float()\n",
    "                \n",
    "                val_predictions.extend(predictions.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_predictions = np.array(val_predictions)\n",
    "        val_labels = np.array(val_labels)\n",
    "        \n",
    "        # Calculate metrics for each category\n",
    "        for i, category in enumerate(toxic_columns):\n",
    "            accuracy = accuracy_score(val_labels[:, i], val_predictions[:, i])\n",
    "            auc = roc_auc_score(val_labels[:, i], val_predictions[:, i])\n",
    "            \n",
    "            results.append({\n",
    "                'Category': category,\n",
    "                'Model': f\"{model_name}_epoch_{epoch+1}\",\n",
    "                'Accuracy': accuracy,\n",
    "                'AUC': auc\n",
    "            })\n",
    "            \n",
    "            print(f\"{category} - Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Prepare data\n",
    "X_train_dense = X_train.toarray()\n",
    "X_val_dense = X_val.toarray()\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = TextClassificationDataset(X_train_dense, y_train)\n",
    "val_dataset = TextClassificationDataset(X_val_dense, y_val)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Initialize models\n",
    "simple_nn = SimpleNN(input_dim=X_train_dense.shape[1])\n",
    "cnn_model = CNNTextClassifier(input_dim=X_train_dense.shape[1])\n",
    "\n",
    "# Training parameters\n",
    "criterion = nn.BCELoss()\n",
    "simple_nn_optimizer = torch.optim.Adam(simple_nn.parameters(), lr=0.001)\n",
    "cnn_optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "# Train models\n",
    "print(\"Training Simple Neural Network...\")\n",
    "nn_results = train_model(\n",
    "    simple_nn, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    criterion, \n",
    "    simple_nn_optimizer,\n",
    "    n_epochs=3,\n",
    "    model_name='SimpleNN'\n",
    ")\n",
    "\n",
    "print(\"\\nTraining CNN Model...\")\n",
    "cnn_results = train_model(\n",
    "    cnn_model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    criterion, \n",
    "    cnn_optimizer,\n",
    "    n_epochs=3,\n",
    "    model_name='CNN'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all results\n",
    "final_results = pd.concat([results_df, nn_results, cnn_results])\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# AUC Scores\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.boxplot(data=final_results, x='Model', y='AUC', hue='Category')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Model Performance Comparison (AUC)')\n",
    "\n",
    "# Accuracy Scores\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.boxplot(data=final_results, x='Model', y='Accuracy', hue='Category')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Model Performance Comparison (Accuracy)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "summary = final_results.groupby(['Model', 'Category'])[['Accuracy', 'AUC']].mean()\n",
    "print(\"\\nModel Performance Summary:\")\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
